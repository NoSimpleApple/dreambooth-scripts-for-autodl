param(
  [switch] $alt=$false
)

$Trainer = "repos/diffusers/examples/dreambooth/train_dreambooth.py"

# https://stackoverflow.com/questions/31879814/check-if-a-file-exists-or-not-in-windows-powershell
if ($alt) {
  Write-Host "Try to use alternative script"
  $Trainer = "repos/diffusers/examples/dreambooth/train_dreambooth_alt.py"
  $exist = Test-Path $Trainer -PathType Leaf
  if (!$exist) {
    Write-Host -ForegroundColor red "Alternative trainer not found. Run 'get_alt_script.ps1' to get it."
    exit 1
  }
} else {
  $exist = Test-Path $Trainer -PathType Leaf
  if (!$exist) {
    Write-Host -ForegroundColor red "Trainer not found. Have you run 'git submodule update --init --recursive'?"
    exit 1
  }
}

$AutoDLTmp = "/root/autodl-tmp"

# maybe use 512?
$Resolution = 768 

$ConfigPath = Join-Path (Invoke-Expression "Get-Location") "dreambooth.yaml"

# Previewing
# Prompt for saving samples.
$SaveSamplePrompt = "sks 1girl standing looking at viewer, cowboy shot" 
$SaveSampleNegative = "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry" 

# TODO: detect if the model exists
# Remind the user to excecute `convert.ps1` if the model is not existing.

# Model path
$ModelName = "animefull-pruned"
# I will dump to auto-tmp to save space of system disk
$ModelPath = Join-Path $AutoDLTmp $ModelName
$VaePath = Join-Path $ModelPath "vae"
$OutPath = Join-Path $AutoDLTmp "output"
mkdir -p $OutPath

# use this setting if you are using A5000 like me

# See https://github.com/CCRcmcpe/diffusers/blob/main/examples/dreambooth/modules/args.py
# for full parameter list
accelerate launch $Trainer `
  --pretrained_model_name_or_path $ModelPath `
  --pretrained_vae_name_or_path $VaePath `
  --output_dir $OutPath `
  <# Everything should be configured here #> `
  --config $ConfigPath
  <# WandB Project Name #> `
  <# --project "test" #> `
  <# ID of this run, random generated by default. #> `
  <# --run_id "test" #> `
  <# would ovrride epochs if provided #> `
  <# --train_n_steps=2000 #> `
  <# target epochs #> `
  --train_to_epochs=50

# `gradient accumulation` will save VRAM but slow it down
# `train_text_encoder` would train text encoder
# increase the batch size if you still got spare VRAM

# TODO: write a script to inference images with parameters like json?
# don't care about inference. I would do it some where else.
# see `back.ps1`
